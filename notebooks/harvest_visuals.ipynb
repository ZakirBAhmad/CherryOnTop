{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import src.preprocessing as pre\n",
    "import plotly.graph_objects as go\n",
    "import src.utils as utils\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, mappings, meta = pre.separate_year('../data/meta.json','../data/y.csv','../data/mappings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_plan = pre.decode(meta,mappings)[['Year','WeekTransplanted','Ranch','Class','Type','Variety','Ha']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 4382907.2223\n",
      "Epoch [2/200], Loss: 3745032.2528\n",
      "Epoch [3/200], Loss: 3165604.0142\n",
      "Epoch [4/200], Loss: 3030348.3949\n",
      "Epoch [5/200], Loss: 2858278.2528\n",
      "Epoch [6/200], Loss: 2664212.1051\n",
      "Epoch [7/200], Loss: 2501671.6406\n",
      "Epoch [8/200], Loss: 2428333.4183\n",
      "Epoch [9/200], Loss: 2380930.5994\n",
      "Epoch [10/200], Loss: 2340200.2230\n",
      "Epoch [11/200], Loss: 2299522.6428\n",
      "Epoch [12/200], Loss: 2273494.2599\n",
      "Epoch [13/200], Loss: 2257141.0781\n",
      "Epoch [14/200], Loss: 2210988.5881\n",
      "Epoch [15/200], Loss: 2182991.4922\n",
      "Epoch [16/200], Loss: 2151938.9538\n",
      "Epoch [17/200], Loss: 2112385.1040\n",
      "Epoch [18/200], Loss: 2080347.7195\n",
      "Epoch [19/200], Loss: 2044036.1896\n",
      "Epoch [20/200], Loss: 2005300.2287\n",
      "Epoch [21/200], Loss: 1981089.7152\n",
      "Epoch [22/200], Loss: 1924149.6168\n",
      "Epoch [23/200], Loss: 1883714.1349\n",
      "Epoch [24/200], Loss: 1850999.5515\n",
      "Epoch [25/200], Loss: 1805585.1445\n",
      "Epoch [26/200], Loss: 1765487.3288\n",
      "Epoch [27/200], Loss: 1735544.3714\n",
      "Epoch [28/200], Loss: 1694341.1058\n",
      "Epoch [29/200], Loss: 1666078.7610\n",
      "Epoch [30/200], Loss: 1643647.2237\n",
      "Epoch [31/200], Loss: 1631338.6101\n",
      "Epoch [32/200], Loss: 1613352.9634\n",
      "Epoch [33/200], Loss: 1596805.1207\n",
      "Epoch [34/200], Loss: 1582990.5749\n",
      "Epoch [35/200], Loss: 1566240.4510\n",
      "Epoch [36/200], Loss: 1556659.6868\n",
      "Epoch [37/200], Loss: 1547459.0234\n",
      "Epoch [38/200], Loss: 1545157.9450\n",
      "Epoch [39/200], Loss: 1535518.7919\n",
      "Epoch [40/200], Loss: 1537641.6641\n",
      "Epoch [41/200], Loss: 1525177.9908\n",
      "Epoch [42/200], Loss: 1514526.2010\n",
      "Epoch [43/200], Loss: 1513671.3718\n",
      "Epoch [44/200], Loss: 1523302.0739\n",
      "Epoch [45/200], Loss: 1506602.7621\n",
      "Epoch [46/200], Loss: 1492222.3315\n",
      "Epoch [47/200], Loss: 1495838.7710\n",
      "Epoch [48/200], Loss: 1481377.8082\n",
      "Epoch [49/200], Loss: 1475897.6772\n",
      "Epoch [50/200], Loss: 1463588.5881\n",
      "Epoch [51/200], Loss: 1450379.9790\n",
      "Epoch [52/200], Loss: 1444228.3201\n",
      "Epoch [53/200], Loss: 1435686.5977\n",
      "Epoch [54/200], Loss: 1432208.0511\n",
      "Epoch [55/200], Loss: 1420230.6264\n",
      "Epoch [56/200], Loss: 1413053.2987\n",
      "Epoch [57/200], Loss: 1405320.7791\n",
      "Epoch [58/200], Loss: 1403146.2482\n",
      "Epoch [59/200], Loss: 1419796.3960\n",
      "Epoch [60/200], Loss: 1392180.9197\n",
      "Epoch [61/200], Loss: 1388386.9769\n",
      "Epoch [62/200], Loss: 1385768.6183\n",
      "Epoch [63/200], Loss: 1368542.0188\n",
      "Epoch [64/200], Loss: 1360008.8093\n",
      "Epoch [65/200], Loss: 1355746.0856\n",
      "Epoch [66/200], Loss: 1344332.1896\n",
      "Epoch [67/200], Loss: 1351476.8544\n",
      "Epoch [68/200], Loss: 1347008.0195\n",
      "Epoch [69/200], Loss: 1329384.6793\n",
      "Epoch [70/200], Loss: 1326353.6900\n",
      "Epoch [71/200], Loss: 1321750.3526\n",
      "Epoch [72/200], Loss: 1326068.4237\n",
      "Epoch [73/200], Loss: 1333583.5355\n",
      "Epoch [74/200], Loss: 1312439.1577\n",
      "Epoch [75/200], Loss: 1301257.1186\n",
      "Epoch [76/200], Loss: 1297696.1332\n",
      "Epoch [77/200], Loss: 1306934.9396\n",
      "Epoch [78/200], Loss: 1312186.6818\n",
      "Epoch [79/200], Loss: 1302718.6470\n",
      "Epoch [80/200], Loss: 1298326.1527\n",
      "Epoch [81/200], Loss: 1295242.7955\n",
      "Epoch [82/200], Loss: 1280774.6932\n",
      "Epoch [83/200], Loss: 1288644.1639\n",
      "Epoch [84/200], Loss: 1274775.6071\n",
      "Epoch [85/200], Loss: 1259630.3079\n",
      "Epoch [86/200], Loss: 1257130.3047\n",
      "Epoch [87/200], Loss: 1265234.0131\n",
      "Epoch [88/200], Loss: 1276626.1246\n",
      "Epoch [89/200], Loss: 1293435.3792\n",
      "Epoch [90/200], Loss: 1278094.4957\n",
      "Epoch [91/200], Loss: 1268278.8654\n",
      "Epoch [92/200], Loss: 1263739.6573\n",
      "Epoch [93/200], Loss: 1262975.1602\n",
      "Epoch [94/200], Loss: 1259311.7287\n",
      "Epoch [95/200], Loss: 1247177.0664\n",
      "Epoch [96/200], Loss: 1262124.6520\n",
      "Epoch [97/200], Loss: 1250015.3899\n",
      "Epoch [98/200], Loss: 1246265.6254\n",
      "Epoch [99/200], Loss: 1245969.6900\n",
      "Epoch [100/200], Loss: 1242657.6200\n"
     ]
    }
   ],
   "source": [
    "model = utils.create_model(train,num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = utils.predict_harvest(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_plan['PredictedTotalKilos'] = preds.sum(axis=1)\n",
    "production_plan['ActualTotalKilos'] = test.Y.detach().numpy().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = production_plan.groupby(['Class','Type']).agg({'Ha':'sum','PredictedTotalKilos':'sum','ActualTotalKilos':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_harvest(_model, _test_dataset):\n",
    "    _model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_predictions = np.zeros((len(_test_dataset), 15,20))\n",
    "        \n",
    "    \n",
    "        test_loader = DataLoader(_test_dataset, batch_size=64, shuffle=False)\n",
    "        for batch in test_loader:\n",
    "            features, ranch_id, class_id, type_id, variety_id, climate_data, y, bounds, idx = batch\n",
    "            batch_size = y.size(0)\n",
    "            log_kilos = torch.log1p(y) \n",
    "            week_numbers = torch.arange(0, 20).unsqueeze(0).repeat(batch_size,1)\n",
    "            inputs = torch.stack([y, log_kilos, week_numbers], dim=2)\n",
    "            for i in range(5,20):\n",
    "                kilo_inputs = inputs[:,:i,:]\n",
    "                outputs = _model(features, ranch_id, class_id, type_id, variety_id, climate_data, kilo_inputs)\n",
    "                test_predictions[idx,i-5,:] = outputs.detach().numpy()\n",
    "\n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict_harvest(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = test.Y.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.76117551e+00, -2.31934190e-01, -2.49751471e-02, ...,\n",
       "         3.82754492e+03,  3.38743896e+03,  2.41216211e+03],\n",
       "       [-1.78795481e+00, -3.30950052e-01, -1.08312540e-01, ...,\n",
       "         2.47356885e+03,  2.14371655e+03,  1.48200110e+03],\n",
       "       [-1.61818945e+00, -2.27434456e-01, -8.10581371e-02, ...,\n",
       "         2.37995557e+03,  2.07076807e+03,  1.43295239e+03],\n",
       "       ...,\n",
       "       [-1.14866352e+00, -2.53558904e-01,  2.14779526e-02, ...,\n",
       "         1.45277954e+03,  1.23839197e+03,  8.76833740e+02],\n",
       "       [-1.01850522e+00, -8.25120509e-02,  2.10033208e-02, ...,\n",
       "         6.27791443e+02,  5.06521423e+02,  3.21959290e+02],\n",
       "       [-1.28657043e+00, -2.28704050e-01, -2.89215967e-02, ...,\n",
       "         1.39987488e+03,  1.17342749e+03,  8.17523499e+02]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cherry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
