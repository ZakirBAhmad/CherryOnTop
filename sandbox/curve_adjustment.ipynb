{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from src.updated_model import HarvestModel\n",
    "from torch.utils.data import DataLoader\n",
    "import src.preprocessing as pre\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta, y, mapping_dict = pre.load_data('../data/planting_meta.json','../data/y.csv','../data/mapping_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class\n",
    "class HarvestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class for handling harvest data.\n",
    "\n",
    "    This dataset manages features and various categorical IDs (ranch, class, type, variety) \n",
    "    along with target variables for kilos measurements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : numpy.ndarray, shape (N, 4)\n",
    "        Static features for N samples (hectares, plants_per_hectare, avg_plant_height, avg_leaf_count)\n",
    "    ranch_ids : numpy.ndarray, shape (N,)\n",
    "        Ranch identifier integers\n",
    "    class_ids : numpy.ndarray, shape (N,)\n",
    "        Class identifier integers\n",
    "    type_ids : numpy.ndarray, shape (N,)\n",
    "        Type identifier integers\n",
    "    variety_ids : numpy.ndarray, shape (N,)\n",
    "        Variety identifier integers\n",
    "    Y_kilos : numpy.ndarray, shape (N, 20)\n",
    "        Target kilos measurements for 20 timesteps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Contains tensors for features, IDs and targets when indexed\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 features,         # (N, 5)\n",
    "                 ranch_ids,        # (N,)\n",
    "                 class_ids,        # (N,)\n",
    "                 type_ids,         # (N,)\n",
    "                 variety_ids,      # (N,)\n",
    "                 climate_data,     # (N, 100, 3)\n",
    "                 Y_kilos,         # (N, 20)\n",
    "                 mean=None,\n",
    "                 std=None\n",
    "                ):\n",
    "    \n",
    "       \n",
    "\n",
    "        # Convert to tensors\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.ranch_ids = torch.tensor(ranch_ids, dtype=torch.long)\n",
    "        self.class_ids = torch.tensor(class_ids, dtype=torch.long)\n",
    "        self.type_ids = torch.tensor(type_ids, dtype=torch.long)\n",
    "        self.variety_ids = torch.tensor(variety_ids, dtype=torch.long)\n",
    "        self.climate_data = torch.tensor(climate_data, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y_kilos, dtype=torch.float32)\n",
    "        nonzero = self.Y != 0\n",
    "\n",
    "        idx = torch.arange(self.Y.size(1)).expand_as(self.Y)\n",
    "        start = torch.where(nonzero, idx, torch.full_like(idx, self.Y.size(1))).min(dim=1).values\n",
    "        end = torch.where(nonzero, idx, torch.full_like(idx, -1)).max(dim=1).values\n",
    "\n",
    "        self.bounds = torch.stack([start, end], dim=1)\n",
    "\n",
    "        self.climate_mean = mean\n",
    "        self.climate_std = std\n",
    "\n",
    "             \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        climate_data = self.climate_data[idx]\n",
    "        if self.climate_mean is not None and self.climate_std is not None:\n",
    "            climate_data = (climate_data - self.climate_mean) / (self.climate_std + 1e-6)\n",
    "        return (\n",
    "            self.features[idx],\n",
    "            self.ranch_ids[idx],\n",
    "            self.class_ids[idx],\n",
    "            self.type_ids[idx],\n",
    "            self.variety_ids[idx],\n",
    "            climate_data,\n",
    "            self.Y[idx],\n",
    "            self.bounds[idx]\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def get_shapes(self):\n",
    "        \"\"\"\n",
    "        Returns a dictionary containing the shapes of all data tensors\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary with tensor names as keys and their shapes as values\n",
    "        \"\"\"\n",
    "        shapes = {\n",
    "            'features': self.features.shape,\n",
    "            'ranch_ids': self.ranch_ids.shape,\n",
    "            'class_ids': self.class_ids.shape,\n",
    "            'type_ids': self.type_ids.shape,\n",
    "            'variety_ids': self.variety_ids.shape,\n",
    "            'climate_data': self.climate_data.shape,\n",
    "            'Y_kilos': self.Y.shape\n",
    "        }\n",
    "        return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.column_stack([\n",
    "    meta['Ha'].to_numpy(),                    # Hectares\n",
    "    meta['WeekTransplanted_sin'].to_numpy(),  # Week sine\n",
    "    meta['WeekTransplanted_cos'].to_numpy(),  # Week cosine\n",
    "    meta['Year'].to_numpy() - 2010,                  # Year\n",
    "    np.ones(len(meta))                    # Constant feature\n",
    "    ])\n",
    "ranches = meta['Ranch'].to_numpy()\n",
    "varieties = meta['Variety'].to_numpy()\n",
    "classes = meta['Class'].to_numpy()\n",
    "types = meta['Type'].to_numpy()\n",
    "climate_data = np.array(meta.ClimateSeries.to_list())\n",
    "y_kilos = y.iloc[:,:20].to_numpy()\n",
    "\n",
    "dataset = HarvestDataset(\n",
    "        features,\n",
    "        ranches,\n",
    "        classes,\n",
    "        types,\n",
    "        varieties,\n",
    "        climate_data,\n",
    "        y_kilos\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create a DataLoader over the entire training set (no shuffle needed)\n",
    "full_train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "\n",
    "# Get all climate data from training set\n",
    "features, ranch_id, class_id, type_id, variety_id, climate_data, y, bounds = next(iter(full_train_loader))\n",
    "\n",
    "# Flatten and compute mean/std on training climate data\n",
    "climate_data_flat = climate_data.view(-1, climate_data.shape[-1])\n",
    "climate_mean = climate_data_flat.mean(dim=0)\n",
    "climate_std = climate_data_flat.std(dim=0)\n",
    "\n",
    "# Assign these stats to train and val datasets\n",
    "train_dataset.dataset.climate_mean = climate_mean  # type: ignore\n",
    "train_dataset.dataset.climate_std = climate_std    # type: ignore\n",
    "val_dataset.dataset.climate_mean = climate_mean    # type: ignore\n",
    "val_dataset.dataset.climate_std = climate_std      # type: ignore\n",
    "\n",
    "# Now create DataLoaders for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HarvestModel(\n",
       "  (encoder): ClimateEncoder(\n",
       "    (feature_encoder): Sequential(\n",
       "      (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (climate_gru): GRU(3, 32, batch_first=True)\n",
       "    (ranch_emb): Embedding(13, 4)\n",
       "    (class_emb): Embedding(2, 4)\n",
       "    (type_emb): Embedding(14, 4)\n",
       "    (variety_emb): Embedding(59, 4)\n",
       "    (type_to_class): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (variety_to_type): Linear(in_features=4, out_features=4, bias=True)\n",
       "  )\n",
       "  (harvest_clamp): Sequential(\n",
       "    (0): Linear(in_features=112, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=2, bias=True)\n",
       "  )\n",
       "  (kilo_gru): GRU(3, 20, batch_first=True)\n",
       "  (kilo_output): Sequential(\n",
       "    (0): Linear(in_features=134, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HarvestModel()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 4786523.6717, Improvement: -43504.8102\n",
      "Epoch [2/50], Loss: 4736850.7244, Improvement: -99622.1827\n",
      "Epoch [3/50], Loss: 4695085.7093, Improvement: 50859.6544\n",
      "Epoch [4/50], Loss: 4606462.7214, Improvement: 91444.7158\n",
      "Epoch [5/50], Loss: 4525387.4428, Improvement: 134583.5979\n",
      "Epoch [6/50], Loss: 4489573.3102, Improvement: 94956.7447\n",
      "Epoch [7/50], Loss: 4429541.0994, Improvement: 205950.9670\n",
      "Epoch [8/50], Loss: 4401808.7440, Improvement: 148980.5407\n",
      "Epoch [9/50], Loss: 4363822.8358, Improvement: 90304.9225\n",
      "Epoch [10/50], Loss: 4321295.7071, Improvement: -54894.5516\n",
      "Epoch [11/50], Loss: 4314992.7756, Improvement: -97795.2593\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs[:,:kilo_range,:]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m outputs, clamp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranch_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariety_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclimate_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m N \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m T \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Should be 20\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Projects/CherryOnTop/src/updated_model.py:57\u001b[0m, in \u001b[0;36mHarvestModel.forward\u001b[0;34m(self, features, ranch_id, class_id, type_id, variety_id, climate_data, kilo_gru_input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features, ranch_id, class_id, type_id, variety_id, climate_data, kilo_gru_input):\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    features: (batch_size, 5)z\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    climate_data: (batch_size, 100, 3)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    kilo_gru_input: (batch_size, [5:20], 3)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranch_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariety_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclimate_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m climate_data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     60\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkilo_gru\u001b[38;5;241m.\u001b[39mhidden_size)\n",
      "File \u001b[0;32m~/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Projects/CherryOnTop/src/encoder.py:66\u001b[0m, in \u001b[0;36mClimateEncoder.forward\u001b[0;34m(self, features, ranch_id, class_id, type_id, variety_id, climate_data)\u001b[0m\n\u001b[1;32m     64\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m climate_data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     65\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclimate_gru\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(climate_data\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 66\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclimate_gru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclimate_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# out: (batch_size, seq_len, hidden_size)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Take last timestep\u001b[39;00m\n\u001b[1;32m     69\u001b[0m climate_out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# (batch_size, climate_hidden_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1393\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1393\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1405\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[1;32m   1406\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1407\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1415\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        features, ranch_id, class_id, type_id, variety_id, climate_data, y, bounds = batch\n",
    "        totals = y.sum().to(dtype=torch.float32)\n",
    "        bounds = bounds.to(dtype=torch.float32)\n",
    "        looped_loss = criterion(y,y)\n",
    "        batch_size = y.size(0)\n",
    "        log_kilos = torch.log1p(y) \n",
    "        week_numbers = torch.arange(0, 20).unsqueeze(0).repeat(batch_size,1)\n",
    "        inputs = torch.stack([y, log_kilos, week_numbers], dim=2)\n",
    "\n",
    "        for kilo_range in torch.randint(low =5,high=20,size=(5,)):\n",
    "    \n",
    "            inputs = inputs[:,:kilo_range,:]\n",
    "            # Forward pass\n",
    "            outputs, clamp = model(features, ranch_id, class_id, type_id, variety_id, climate_data, inputs)\n",
    "            N = outputs.size(0)\n",
    "            T = outputs.size(1)  # Should be 20\n",
    "\n",
    "            # Create time indices [0, 1, ..., 19] and expand to shape (N, 20)\n",
    "            time = torch.arange(T).unsqueeze(0).expand(N, T)\n",
    "\n",
    "            # Get start and end indices\n",
    "            start = clamp[:, 0].unsqueeze(1)  # Shape: (N, 1)\n",
    "            end = clamp[:, 1].unsqueeze(1)    # Shape: (N, 1)\n",
    "\n",
    "            # Create mask: 1 where i is within [start, end), 0 elsewhere\n",
    "            mask = (time >= start) & (time < end)  # Shape: (N, 20)\n",
    "\n",
    "            # Apply mask\n",
    "            masked_harvests = outputs * mask\n",
    "            loss_kilos = criterion(masked_harvests[:,kilo_range:], y[:,kilo_range:])\n",
    "            loss_clamp = criterion(clamp/20, bounds/20)\n",
    "\n",
    "            loss = loss_kilos + loss_clamp * totals\n",
    "            looped_loss += loss\n",
    "\n",
    "            # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        looped_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += looped_loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{50}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cherry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
