{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta, weekly_summary, mapping_dict = pre.load_tomato(planting_meta_path='../data/planting_meta.json', weekly_summary_path='../data/weekly_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransplantDate</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekTransplanted</th>\n",
       "      <th>Ranch</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Class</th>\n",
       "      <th>Type</th>\n",
       "      <th>Ha</th>\n",
       "      <th>WeekTransplanted_sin</th>\n",
       "      <th>WeekTransplanted_cos</th>\n",
       "      <th>ClimateSeries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-13_Felicity_ZJL_Z18_6_0.39</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Felicity</td>\n",
       "      <td>CHE</td>\n",
       "      <td>Cherry Rojo</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>[[-0.5605881878, -3.1935067896000002, -0.25850...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-13_Shiren_ZJL_Z18_6_0.39</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Shiren</td>\n",
       "      <td>CHE</td>\n",
       "      <td>Cherry Rojo</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>[[-0.5605881878, -3.1935067896000002, -0.25850...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-15_Amsterdam_ZJL_Z18_2_0.27</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>BSUF</td>\n",
       "      <td>Uva Roja</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>[[0.3146673828, -1.2573452111, -0.258501094600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-15_Felicity_ZJL_Z18_5_0.21</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Felicity</td>\n",
       "      <td>CHE</td>\n",
       "      <td>Cherry Rojo</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>[[0.3146673828, -1.2573452111, -0.258501094600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-15_Olivia_ZJL_Z18_2_0.54</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>BSUF</td>\n",
       "      <td>Uva Roja</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>[[0.3146673828, -1.2573452111, -0.258501094600...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    TransplantDate  Year  WeekTransplanted  \\\n",
       "2013-02-13_Felicity_ZJL_Z18_6_0.39      2013-02-13  2013                 7   \n",
       "2013-02-13_Shiren_ZJL_Z18_6_0.39        2013-02-13  2013                 7   \n",
       "2013-02-15_Amsterdam_ZJL_Z18_2_0.27     2013-02-15  2013                 7   \n",
       "2013-02-15_Felicity_ZJL_Z18_5_0.21      2013-02-15  2013                 7   \n",
       "2013-02-15_Olivia_ZJL_Z18_2_0.54        2013-02-15  2013                 7   \n",
       "\n",
       "                                    Ranch    Variety Class         Type  \\\n",
       "2013-02-13_Felicity_ZJL_Z18_6_0.39    ZJL   Felicity   CHE  Cherry Rojo   \n",
       "2013-02-13_Shiren_ZJL_Z18_6_0.39      ZJL     Shiren   CHE  Cherry Rojo   \n",
       "2013-02-15_Amsterdam_ZJL_Z18_2_0.27   ZJL  Amsterdam  BSUF     Uva Roja   \n",
       "2013-02-15_Felicity_ZJL_Z18_5_0.21    ZJL   Felicity   CHE  Cherry Rojo   \n",
       "2013-02-15_Olivia_ZJL_Z18_2_0.54      ZJL     Olivia  BSUF     Uva Roja   \n",
       "\n",
       "                                         Ha  WeekTransplanted_sin  \\\n",
       "2013-02-13_Felicity_ZJL_Z18_6_0.39   0.3938              0.748511   \n",
       "2013-02-13_Shiren_ZJL_Z18_6_0.39     0.3938              0.748511   \n",
       "2013-02-15_Amsterdam_ZJL_Z18_2_0.27  0.2700              0.748511   \n",
       "2013-02-15_Felicity_ZJL_Z18_5_0.21   0.2138              0.748511   \n",
       "2013-02-15_Olivia_ZJL_Z18_2_0.54     0.5400              0.748511   \n",
       "\n",
       "                                     WeekTransplanted_cos  \\\n",
       "2013-02-13_Felicity_ZJL_Z18_6_0.39               0.663123   \n",
       "2013-02-13_Shiren_ZJL_Z18_6_0.39                 0.663123   \n",
       "2013-02-15_Amsterdam_ZJL_Z18_2_0.27              0.663123   \n",
       "2013-02-15_Felicity_ZJL_Z18_5_0.21               0.663123   \n",
       "2013-02-15_Olivia_ZJL_Z18_2_0.54                 0.663123   \n",
       "\n",
       "                                                                         ClimateSeries  \n",
       "2013-02-13_Felicity_ZJL_Z18_6_0.39   [[-0.5605881878, -3.1935067896000002, -0.25850...  \n",
       "2013-02-13_Shiren_ZJL_Z18_6_0.39     [[-0.5605881878, -3.1935067896000002, -0.25850...  \n",
       "2013-02-15_Amsterdam_ZJL_Z18_2_0.27  [[0.3146673828, -1.2573452111, -0.258501094600...  \n",
       "2013-02-15_Felicity_ZJL_Z18_5_0.21   [[0.3146673828, -1.2573452111, -0.258501094600...  \n",
       "2013-02-15_Olivia_ZJL_Z18_2_0.54     [[0.3146673828, -1.2573452111, -0.258501094600...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = weekly_summary.pivot(columns='WeeksAfterTransplant', values='Kilos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta[df.sum(axis=1) > 400]\n",
    "df = df[df.sum(axis=1) > 400]\n",
    "df = df[df.nunique(axis=1) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = df.fillna(0).T.rolling(window=3,min_periods=1).mean()\n",
    "smoothed = smoothed * df.sum(axis=1) / smoothed.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = smoothed.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(t, K, r, t0):\n",
    "    return K / (1 + np.exp(-r * (t - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i, row in smoothed.iterrows():\n",
    "    y = row.cumsum().to_numpy()\n",
    "    total_kilos = y[-1]\n",
    "    x = np.arange(20)\n",
    "    k0 = total_kilos\n",
    "    r0 = 0.01\n",
    "    t0 = 10\n",
    "    p0 = [k0,r0,t0]\n",
    "    bounds = (\n",
    "    [total_kilos * 0.95, 1e-4, 0],   # lower bounds\n",
    "    [total_kilos * 1.05, 1.5, len(x)]  # upper bounds\n",
    ")\n",
    "    try:\n",
    "        popt,pcov = curve_fit(logistic,x,y,p0=p0,bounds=bounds)\n",
    "    except:\n",
    "        print(y)\n",
    "        continue\n",
    "    perr = np.sqrt(np.diag(pcov))           # standard deviation of parameters\n",
    "    delta = 1.96 * perr                     # 95% confidence interval half-width\n",
    "    results.append([popt,delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pd.DataFrame([np.array(a).flatten() for a in results],columns=['K','r','t','K_err','r_err','t_err'],index=smoothed.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([smoothed,rf],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.0000e+00, 1.6138e+01, 2.7221e+02, 4.3204e+02, 2.0727e+03, 2.0727e+03,\n",
       "        1.6407e+03, 8.7467e+02, 1.3333e+03, 1.9027e+03, 3.6467e+03, 6.8399e+03,\n",
       "        9.0795e+03, 1.0058e+04, 1.1846e+04, 1.1675e+04, 1.4300e+04, 1.4709e+04,\n",
       "        1.5432e+04, 1.6749e+04, 7.6055e+04, 1.5000e+00, 1.8136e+01, 1.0914e+04,\n",
       "        1.6058e+00, 6.2950e+00], dtype=torch.float64),\n",
       "indices=tensor([   0,  767,  500,  740,  740,  740,  740,  435, 3286, 3255, 3255,  763,\n",
       "         503,  503,  438,  411,  411, 1677, 3053, 3053, 3053,  168, 3160,  177,\n",
       "        2328,  686]))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(df1.values).max(dim=0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct A Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "#class\n",
    "class HarvestDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 features,         # (N, 5)\n",
    "                 ranch_ids,        # (N,)\n",
    "                 class_ids,        # (N,)\n",
    "                 type_ids,         # (N,)\n",
    "                 variety_ids,      # (N,)\n",
    "                 climate_data,     # (N, 100, 3)\n",
    "                 Y_kilos = None,          # (N, 20)\n",
    "                 stats = None          # (N, 6)\n",
    "                ):\n",
    "    \n",
    "\n",
    "        # Convert to tensors\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.ranch_ids = torch.tensor(ranch_ids, dtype=torch.long)\n",
    "        self.class_ids = torch.tensor(class_ids, dtype=torch.long)\n",
    "        self.type_ids = torch.tensor(type_ids, dtype=torch.long)\n",
    "        self.variety_ids = torch.tensor(variety_ids, dtype=torch.long)\n",
    "        self.climate_data = torch.tensor(climate_data, dtype=torch.float32)\n",
    "        Y_kilos = torch.tensor(Y_kilos, dtype=torch.float32)\n",
    "        stats = torch.tensor(stats, dtype=torch.float32)\n",
    "        self.outputs = torch.cat((Y_kilos, stats), dim=1)\n",
    "        self.means = self.outputs.mean(dim=0)\n",
    "        self.denom = 2*(self.outputs.max(dim=0).values - self.outputs.min(dim=0).values)\n",
    "        self.Y = (self.outputs - self.means) / self.denom\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def get_shapes(self):\n",
    "        \"\"\"\n",
    "        Returns a dictionary containing the shapes of all data tensors\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary with tensor names as keys and their shapes as values\n",
    "        \"\"\"\n",
    "        shapes = {\n",
    "            'features': self.features.shape,\n",
    "            'ranch_ids': self.ranch_ids.shape,\n",
    "            'class_ids': self.class_ids.shape,\n",
    "            'type_ids': self.type_ids.shape,\n",
    "            'variety_ids': self.variety_ids.shape,\n",
    "            'Y_kilos': self.Y_kilos.shape\n",
    "        }\n",
    "        return shapes\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.features[idx],\n",
    "            self.ranch_ids[idx],\n",
    "            self.class_ids[idx],\n",
    "            self.type_ids[idx],\n",
    "            self.variety_ids[idx],\n",
    "            self.climate_data[idx],\n",
    "            self.Y[idx]\n",
    "        )\n",
    "    \n",
    "    def revert(self, arr):\n",
    "        return arr * self.denom + self.means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ClimateEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim=5,\n",
    "                 embedding_dim=4,\n",
    "                 hidden_dim=64,\n",
    "                 n_ranches=13,\n",
    "                 n_classes=2,\n",
    "                 n_types=14,\n",
    "                 n_varieties=59,\n",
    "                 climate_input_dim=3,\n",
    "                 climate_hidden_dim=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # Feature processing\n",
    "        self.feature_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Climate GRU\n",
    "        self.climate_gru = nn.GRU(\n",
    "            input_size=climate_input_dim,      # 3 features: temp_max, temp_min, precipitation\n",
    "            hidden_size=climate_hidden_dim,     # You choose (maybe 32)\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Embedding dimensions\n",
    "        self.ranch_dim = embedding_dim  # 12 ranches\n",
    "        self.class_dim = embedding_dim  # 2 classes\n",
    "        self.type_dim = embedding_dim  # 14 types\n",
    "        self.variety_dim = embedding_dim  # 38 varieties\n",
    "\n",
    "        self.ranch_emb = nn.Embedding(n_ranches, self.ranch_dim)\n",
    "        self.class_emb = nn.Embedding(n_classes, self.class_dim)\n",
    "        self.type_emb = nn.Embedding(n_types, self.type_dim)\n",
    "        self.variety_emb = nn.Embedding(n_varieties, self.variety_dim)\n",
    "\n",
    "        self.type_to_class = nn.Linear(self.type_dim, self.class_dim)\n",
    "        self.variety_to_type = nn.Linear(self.variety_dim, self.type_dim)\n",
    "\n",
    "        self.combined_dim = (\n",
    "            hidden_dim +             # static features\n",
    "            climate_hidden_dim +     # output from GRU\n",
    "            self.ranch_dim + \n",
    "            self.class_dim + \n",
    "            self.type_dim + \n",
    "            self.variety_dim\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, features, ranch_id, class_id, type_id, variety_id, climate_data):\n",
    "        \"\"\"\n",
    "        features: (batch_size, 5)\n",
    "        climate_data: (batch_size, 100, 3)\n",
    "        \"\"\"\n",
    "\n",
    "        # Static feature encoder\n",
    "        h_features = self.feature_encoder(features)\n",
    "\n",
    "        # Climate GRU\n",
    "        batch_size = climate_data.size(0)\n",
    "        h0 = torch.zeros(1, batch_size, self.climate_gru.hidden_size).to(climate_data.device)\n",
    "        out, _ = self.climate_gru(climate_data, h0)  # out: (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        # Take last timestep\n",
    "        climate_out = out[:, -1, :]  # (batch_size, climate_hidden_dim)\n",
    "\n",
    "        # Embeddings\n",
    "        r_emb = self.ranch_emb(ranch_id)\n",
    "        c_emb = self.class_emb(class_id)\n",
    "        t_emb = self.type_emb(type_id)\n",
    "        v_emb = self.variety_emb(variety_id)\n",
    "\n",
    "        # Hierarchy\n",
    "        v_influence_on_type = self.variety_to_type(v_emb)\n",
    "        t_emb = t_emb + v_influence_on_type\n",
    "\n",
    "        t_influence_on_class = self.type_to_class(t_emb)\n",
    "        c_emb = c_emb + t_influence_on_class\n",
    "\n",
    "        # Combine all features\n",
    "        combined = torch.cat([\n",
    "            h_features,\n",
    "            climate_out,\n",
    "            r_emb,\n",
    "            c_emb,\n",
    "            t_emb,\n",
    "            v_emb\n",
    "        ], dim=-1)\n",
    "\n",
    "        return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsPredictor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder_dim,\n",
    "                 hidden_dim = 32,   \n",
    "                 output_dim = 6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.stats_predictor = nn.Sequential(\n",
    "            nn.Linear(encoder_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, encoding):\n",
    "        \"\"\"\n",
    "        encoding: (batch_size, encoder_dim)\n",
    "        \"\"\"\n",
    "        return self.stats_predictor(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HarvestModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim=5,\n",
    "                 hidden_dim=64,\n",
    "                 embedding_dim=4,\n",
    "                 n_ranches=13,\n",
    "                 n_classes=2,\n",
    "                 n_types=14,\n",
    "                 n_varieties=59,\n",
    "                 climate_input_dim=3,\n",
    "                 climate_hidden_dim=32,\n",
    "                 output_dim=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = ClimateEncoder(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            embedding_dim=embedding_dim,\n",
    "            n_ranches=n_ranches,\n",
    "            n_classes=n_classes,\n",
    "            n_types=n_types,\n",
    "            n_varieties=n_varieties,\n",
    "            climate_input_dim=climate_input_dim,\n",
    "            climate_hidden_dim=climate_hidden_dim\n",
    "        )\n",
    "\n",
    "        self.stats_predictor = StatsPredictor(\n",
    "            encoder_dim=self.encoder.combined_dim\n",
    "        )\n",
    "\n",
    "        self.t = torch.arange(output_dim)\n",
    "\n",
    "        self.final_kilos = nn.Sequential(\n",
    "            nn.Linear(self.encoder.combined_dim + output_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim+self.stats_predictor.output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, features, ranch_id, class_id, type_id, variety_id, climate_data):\n",
    "        \"\"\"\n",
    "        features: (batch_size, 5)\n",
    "        climate_data: (batch_size, 100, 3)\n",
    "        \"\"\"\n",
    "        encoded = self.encoder(features, ranch_id, class_id, type_id, variety_id, climate_data)\n",
    "\n",
    "        o2 = self.stats_predictor(encoded)\n",
    "        pmf = self.logistic_pmf(o2)\n",
    "\n",
    "        together = torch.cat((encoded,pmf),dim=1)\n",
    "        o1 = self.final_kilos(together)\n",
    "\n",
    "        return torch.cat((o1,o2),dim=1)\n",
    "\n",
    "\n",
    "    def logistic_pmf(self, X) -> torch.Tensor:\n",
    "        # Step 1: compute cumulative logistic\n",
    "        K = X[0]\n",
    "        r = X[1]\n",
    "        t0 = X[2]\n",
    "        cumulative = K / (1 + torch.exp(-r * (self.t - t0)))\n",
    "        \n",
    "        # Step 2: approximate PMF as discrete difference\n",
    "        pmf = torch.diff(cumulative, prepend=torch.tensor([0.0], dtype=cumulative.dtype))\n",
    "        \n",
    "        return pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_harvest_model(train_dataset, num_epochs=5, batch_size=32, lr=1e-3):\n",
    "    \n",
    "    # Create DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize Model\n",
    "    model = HarvestModel()\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            features, ranch_id, class_id, type_id, variety_id, climate_data, Y = batch\n",
    "\n",
    "    \n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features, ranch_id, class_id, type_id, variety_id, climate_data)\n",
    "            loss = criterion(outputs, Y)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'HarvestDataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[192], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_harvest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[188], line 4\u001b[0m, in \u001b[0;36mtrain_harvest_model\u001b[0;34m(train_dataset, num_epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_harvest_model\u001b[39m(train_dataset, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Create DataLoader\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Initialize Model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     model \u001b[38;5;241m=\u001b[39m HarvestModel()\n",
      "File \u001b[0;32m~/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/utils/data/dataloader.py:383\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 383\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/utils/data/sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m     )\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/utils/data/sampler.py:173\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnum_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# dataset size might change at runtime\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'HarvestDataset' has no len()"
     ]
    }
   ],
   "source": [
    "train_harvest_model(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.column_stack([\n",
    "        meta['Ha'].values,                    # Hectares\n",
    "        meta['WeekTransplanted_sin'].values,  # Week sine\n",
    "        meta['WeekTransplanted_cos'].values,  # Week cosine\n",
    "        meta['Year'].values,                  # Year\n",
    "        np.ones(len(meta))                    # Constant feature\n",
    "    ])\n",
    "climate_data = np.stack(meta['ClimateSeries'].values)\n",
    "\n",
    "ranch_ids = meta['Ranch'].map(mapping_dict['Ranch']).values\n",
    "class_ids = meta['Class'].map(mapping_dict['Class']).values\n",
    "type_ids = meta['Type'].map(mapping_dict['Type']).values\n",
    "variety_ids = meta['Variety'].map(mapping_dict['Variety']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HarvestDataset(\n",
    "        features=features,\n",
    "        ranch_ids=ranch_ids,\n",
    "        class_ids=class_ids,\n",
    "        type_ids=type_ids,\n",
    "        variety_ids=variety_ids,\n",
    "        climate_data=climate_data,\n",
    "        Y_kilos=  smoothed.values,\n",
    "        stats = rf.values\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cherry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
