{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.preprocessing as pre\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta, weekly_summary, mapping_dict = pre.load_tomato(planting_meta_path='../data/planting_meta.json', weekly_summary_path='../data/weekly_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransplantDate</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekTransplanted</th>\n",
       "      <th>Ranch</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Class</th>\n",
       "      <th>Type</th>\n",
       "      <th>Ha</th>\n",
       "      <th>WeekTransplanted_sin</th>\n",
       "      <th>WeekTransplanted_cos</th>\n",
       "      <th>ClimateSeries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-13_Felicity_ZJL_Z18_6_0.39</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Felicity</td>\n",
       "      <td>CHE</td>\n",
       "      <td>Cherry Rojo</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>[[-0.5605881878, -3.1935067896000002, -0.25850...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-13_Shiren_ZJL_Z18_6_0.39</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Shiren</td>\n",
       "      <td>CHE</td>\n",
       "      <td>Cherry Rojo</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>[[-0.5605881878, -3.1935067896000002, -0.25850...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-15_Amsterdam_ZJL_Z18_2_0.27</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>BSUF</td>\n",
       "      <td>Uva Roja</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>[[0.3146673828, -1.2573452111, -0.258501094600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-15_Felicity_ZJL_Z18_5_0.21</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Felicity</td>\n",
       "      <td>CHE</td>\n",
       "      <td>Cherry Rojo</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>[[0.3146673828, -1.2573452111, -0.258501094600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-15_Olivia_ZJL_Z18_2_0.54</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>BSUF</td>\n",
       "      <td>Uva Roja</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>[[0.3146673828, -1.2573452111, -0.258501094600...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    TransplantDate  Year  WeekTransplanted  \\\n",
       "2013-02-13_Felicity_ZJL_Z18_6_0.39      2013-02-13  2013                 7   \n",
       "2013-02-13_Shiren_ZJL_Z18_6_0.39        2013-02-13  2013                 7   \n",
       "2013-02-15_Amsterdam_ZJL_Z18_2_0.27     2013-02-15  2013                 7   \n",
       "2013-02-15_Felicity_ZJL_Z18_5_0.21      2013-02-15  2013                 7   \n",
       "2013-02-15_Olivia_ZJL_Z18_2_0.54        2013-02-15  2013                 7   \n",
       "\n",
       "                                    Ranch    Variety Class         Type  \\\n",
       "2013-02-13_Felicity_ZJL_Z18_6_0.39    ZJL   Felicity   CHE  Cherry Rojo   \n",
       "2013-02-13_Shiren_ZJL_Z18_6_0.39      ZJL     Shiren   CHE  Cherry Rojo   \n",
       "2013-02-15_Amsterdam_ZJL_Z18_2_0.27   ZJL  Amsterdam  BSUF     Uva Roja   \n",
       "2013-02-15_Felicity_ZJL_Z18_5_0.21    ZJL   Felicity   CHE  Cherry Rojo   \n",
       "2013-02-15_Olivia_ZJL_Z18_2_0.54      ZJL     Olivia  BSUF     Uva Roja   \n",
       "\n",
       "                                         Ha  WeekTransplanted_sin  \\\n",
       "2013-02-13_Felicity_ZJL_Z18_6_0.39   0.3938              0.748511   \n",
       "2013-02-13_Shiren_ZJL_Z18_6_0.39     0.3938              0.748511   \n",
       "2013-02-15_Amsterdam_ZJL_Z18_2_0.27  0.2700              0.748511   \n",
       "2013-02-15_Felicity_ZJL_Z18_5_0.21   0.2138              0.748511   \n",
       "2013-02-15_Olivia_ZJL_Z18_2_0.54     0.5400              0.748511   \n",
       "\n",
       "                                     WeekTransplanted_cos  \\\n",
       "2013-02-13_Felicity_ZJL_Z18_6_0.39               0.663123   \n",
       "2013-02-13_Shiren_ZJL_Z18_6_0.39                 0.663123   \n",
       "2013-02-15_Amsterdam_ZJL_Z18_2_0.27              0.663123   \n",
       "2013-02-15_Felicity_ZJL_Z18_5_0.21               0.663123   \n",
       "2013-02-15_Olivia_ZJL_Z18_2_0.54                 0.663123   \n",
       "\n",
       "                                                                         ClimateSeries  \n",
       "2013-02-13_Felicity_ZJL_Z18_6_0.39   [[-0.5605881878, -3.1935067896000002, -0.25850...  \n",
       "2013-02-13_Shiren_ZJL_Z18_6_0.39     [[-0.5605881878, -3.1935067896000002, -0.25850...  \n",
       "2013-02-15_Amsterdam_ZJL_Z18_2_0.27  [[0.3146673828, -1.2573452111, -0.258501094600...  \n",
       "2013-02-15_Felicity_ZJL_Z18_5_0.21   [[0.3146673828, -1.2573452111, -0.258501094600...  \n",
       "2013-02-15_Olivia_ZJL_Z18_2_0.54     [[0.3146673828, -1.2573452111, -0.258501094600...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = weekly_summary.pivot(columns='WeeksAfterTransplant', values='Kilos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.sum(axis=1) > 400]\n",
    "df = df[df.nunique(axis=1) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.loc[df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = df.fillna(0).T.rolling(window=3,min_periods=1).mean()\n",
    "smoothed = smoothed * df.sum(axis=1) / smoothed.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = smoothed.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(t, K, r, t0):\n",
    "    return K / (1 + np.exp(-r * (t - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i, row in smoothed.iterrows():\n",
    "    y = row.cumsum().to_numpy()\n",
    "    total_kilos = y[-1]\n",
    "    x = np.arange(20)\n",
    "    k0 = total_kilos\n",
    "    r0 = 0.01\n",
    "    t0 = 10\n",
    "    p0 = [k0,r0,t0]\n",
    "    bounds = (\n",
    "    [total_kilos * 0.95, 1e-4, 0],   # lower bounds\n",
    "    [total_kilos * 1.05, 1.5, len(x)]  # upper bounds\n",
    ")\n",
    "    try:\n",
    "        popt,pcov = curve_fit(logistic,x,y,p0=p0,bounds=bounds)\n",
    "    except:\n",
    "        print(y)\n",
    "        continue\n",
    "    perr = np.sqrt(np.diag(pcov))           # standard deviation of parameters\n",
    "    delta = 1.96 * perr                     # 95% confidence interval half-width\n",
    "    results.append([popt,delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pd.DataFrame([np.array(a).flatten() for a in results],columns=['K','r','t','K_err','r_err','t_err'],index=smoothed.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([smoothed,rf],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 1.6138e+01, 2.7221e+02, 4.3204e+02, 2.0727e+03, 2.0727e+03,\n",
       "        1.6407e+03, 8.7467e+02, 1.3333e+03, 1.9027e+03, 3.6467e+03, 6.8399e+03,\n",
       "        9.0795e+03, 1.0058e+04, 1.1846e+04, 1.1675e+04, 1.4300e+04, 1.4709e+04,\n",
       "        1.5432e+04, 1.6749e+04, 7.6055e+04, 1.5000e+00, 1.8136e+01, 1.0914e+04,\n",
       "        1.6058e+00, 6.2950e+00], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(df1.values).max(dim=0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct A Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "#class\n",
    "class HarvestDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 features,         # (N, 5)\n",
    "                 ranch_ids,        # (N,)\n",
    "                 class_ids,        # (N,)\n",
    "                 type_ids,         # (N,)\n",
    "                 variety_ids,      # (N,)\n",
    "                 climate_data,     # (N, 100, 3)\n",
    "                 Y_kilos = None,          # (N, 20)\n",
    "                 stats = None          # (N, 6)\n",
    "                ):\n",
    "    \n",
    "\n",
    "        # Convert to tensors\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.ranch_ids = torch.tensor(ranch_ids, dtype=torch.long)\n",
    "        self.class_ids = torch.tensor(class_ids, dtype=torch.long)\n",
    "        self.type_ids = torch.tensor(type_ids, dtype=torch.long)\n",
    "        self.variety_ids = torch.tensor(variety_ids, dtype=torch.long)\n",
    "        self.climate_data = torch.tensor(climate_data, dtype=torch.float32)\n",
    "        Y_kilos = torch.tensor(Y_kilos, dtype=torch.float32)\n",
    "        stats = torch.tensor(stats, dtype=torch.float32)\n",
    "        self.outputs = torch.cat((Y_kilos, stats), dim=1)\n",
    "        self.means = self.outputs.mean(dim=0)\n",
    "        self.denom = 2*(self.outputs.max(dim=0).values - self.outputs.min(dim=0).values) + 1e-6\n",
    "        self.Y = (self.outputs - self.means) / self.denom\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def get_shapes(self):\n",
    "        \"\"\"\n",
    "        Returns a dictionary containing the shapes of all data tensors\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary with tensor names as keys and their shapes as values\n",
    "        \"\"\"\n",
    "        shapes = {\n",
    "            'features': self.features.shape,\n",
    "            'ranch_ids': self.ranch_ids.shape,\n",
    "            'class_ids': self.class_ids.shape,\n",
    "            'type_ids': self.type_ids.shape,\n",
    "            'variety_ids': self.variety_ids.shape,\n",
    "            'Y_kilos': self.Y.shape\n",
    "        }\n",
    "        return shapes\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.features[idx],\n",
    "            self.ranch_ids[idx],\n",
    "            self.class_ids[idx],\n",
    "            self.type_ids[idx],\n",
    "            self.variety_ids[idx],\n",
    "            self.climate_data[idx],\n",
    "            self.Y[idx]\n",
    "        )\n",
    "    \n",
    "    def revert(self, arr):\n",
    "        return arr * self.denom + self.means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ClimateEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim=5,\n",
    "                 embedding_dim=4,\n",
    "                 hidden_dim=64,\n",
    "                 n_ranches=13,\n",
    "                 n_classes=2,\n",
    "                 n_types=14,\n",
    "                 n_varieties=59,\n",
    "                 climate_input_dim=3,\n",
    "                 climate_hidden_dim=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # Feature processing\n",
    "        self.feature_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Climate GRU\n",
    "        self.climate_gru = nn.GRU(\n",
    "            input_size=climate_input_dim,      # 3 features: temp_max, temp_min, precipitation\n",
    "            hidden_size=climate_hidden_dim,     # You choose (maybe 32)\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Embedding dimensions\n",
    "        self.ranch_dim = embedding_dim  # 12 ranches\n",
    "        self.class_dim = embedding_dim  # 2 classes\n",
    "        self.type_dim = embedding_dim  # 14 types\n",
    "        self.variety_dim = embedding_dim  # 38 varieties\n",
    "\n",
    "        self.ranch_emb = nn.Embedding(n_ranches, self.ranch_dim)\n",
    "        self.class_emb = nn.Embedding(n_classes, self.class_dim)\n",
    "        self.type_emb = nn.Embedding(n_types, self.type_dim)\n",
    "        self.variety_emb = nn.Embedding(n_varieties, self.variety_dim)\n",
    "\n",
    "        self.type_to_class = nn.Linear(self.type_dim, self.class_dim)\n",
    "        self.variety_to_type = nn.Linear(self.variety_dim, self.type_dim)\n",
    "\n",
    "        self.combined_dim = (\n",
    "            hidden_dim +             # static features\n",
    "            climate_hidden_dim +     # output from GRU\n",
    "            self.ranch_dim + \n",
    "            self.class_dim + \n",
    "            self.type_dim + \n",
    "            self.variety_dim\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, features, ranch_id, class_id, type_id, variety_id, climate_data):\n",
    "        \"\"\"\n",
    "        features: (batch_size, 5)\n",
    "        climate_data: (batch_size, 100, 3)\n",
    "        \"\"\"\n",
    "\n",
    "        # Static feature encoder\n",
    "        h_features = self.feature_encoder(features)\n",
    "\n",
    "        # Climate GRU\n",
    "        batch_size = climate_data.size(0)\n",
    "        h0 = torch.zeros(1, batch_size, self.climate_gru.hidden_size).to(climate_data.device)\n",
    "        out, _ = self.climate_gru(climate_data, h0)  # out: (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        # Take last timestep\n",
    "        climate_out = out[:, -1, :]  # (batch_size, climate_hidden_dim)\n",
    "\n",
    "        # Embeddings\n",
    "        r_emb = self.ranch_emb(ranch_id)\n",
    "        c_emb = self.class_emb(class_id)\n",
    "        t_emb = self.type_emb(type_id)\n",
    "        v_emb = self.variety_emb(variety_id)\n",
    "\n",
    "        # Hierarchy\n",
    "        v_influence_on_type = self.variety_to_type(v_emb)\n",
    "        t_emb = t_emb + v_influence_on_type\n",
    "\n",
    "        t_influence_on_class = self.type_to_class(t_emb)\n",
    "        c_emb = c_emb + t_influence_on_class\n",
    "\n",
    "        # Combine all features\n",
    "        combined = torch.cat([\n",
    "            h_features,\n",
    "            climate_out,\n",
    "            r_emb,\n",
    "            c_emb,\n",
    "            t_emb,\n",
    "            v_emb\n",
    "        ], dim=-1)\n",
    "\n",
    "        return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsPredictor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder_dim,\n",
    "                 hidden_dim = 32,   \n",
    "                 output_dim = 6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.stats_predictor = nn.Sequential(\n",
    "            nn.Linear(encoder_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, encoding):\n",
    "        \"\"\"\n",
    "        encoding: (batch_size, encoder_dim)\n",
    "        \"\"\"\n",
    "        return self.stats_predictor(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HarvestModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim=5,\n",
    "                 hidden_dim=64,\n",
    "                 embedding_dim=4,\n",
    "                 n_ranches=13,\n",
    "                 n_classes=2,\n",
    "                 n_types=14,\n",
    "                 n_varieties=59,\n",
    "                 climate_input_dim=3,\n",
    "                 climate_hidden_dim=32,\n",
    "                 output_dim=20):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.encoder = ClimateEncoder(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            embedding_dim=embedding_dim,\n",
    "            n_ranches=n_ranches,\n",
    "            n_classes=n_classes,\n",
    "            n_types=n_types,\n",
    "            n_varieties=n_varieties,\n",
    "            climate_input_dim=climate_input_dim,\n",
    "            climate_hidden_dim=climate_hidden_dim\n",
    "        )\n",
    "\n",
    "        self.stats_predictor = StatsPredictor(\n",
    "            encoder_dim=self.encoder.combined_dim\n",
    "        )\n",
    "        self.t = torch.arange(output_dim, dtype=torch.float)\n",
    "        \n",
    "        self.final_kilos = nn.Sequential(\n",
    "            nn.Linear(self.encoder.combined_dim + output_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, features, ranch_id, class_id, type_id, variety_id, climate_data):\n",
    "        \"\"\"\n",
    "        features: (batch_size, 5)\n",
    "        climate_data: (batch_size, 100, 3)\n",
    "        \"\"\"\n",
    "        encoded = self.encoder(features, ranch_id, class_id, type_id, variety_id, climate_data)\n",
    "\n",
    "        o2 = self.stats_predictor(encoded)\n",
    "        pmf = torch.stack([self.logistic_pmf(o) for o in o2])\n",
    "        together = torch.cat((encoded,pmf),dim=1)\n",
    "        o1 = self.final_kilos(together)\n",
    "        return torch.cat((o1,o2),dim=1)\n",
    "\n",
    "\n",
    "    def logistic_pmf(self, X) -> torch.Tensor:\n",
    "        # Safe clamp ranges to prevent NaNs\n",
    "        K = torch.clamp(X[0], min=1e-3, max=1e4)\n",
    "        r = torch.clamp(X[1], min=1e-4, max=10.0)\n",
    "        t0 = torch.clamp(X[2], min=0.0, max=float(self.t[-1]))\n",
    "\n",
    "        t = self.t\n",
    "        cumulative = K / (1 + torch.exp(-r * (t - t0)))\n",
    "\n",
    "        prepend_val = torch.zeros(1, dtype=cumulative.dtype, device=cumulative.device)\n",
    "        pmf = torch.diff(cumulative, prepend=prepend_val)\n",
    "\n",
    "        return pmf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.column_stack([\n",
    "        np.array(meta['Ha'].values),                    # Hectares\n",
    "        np.array(meta['WeekTransplanted_sin'].values),  # Week sine\n",
    "        np.array(meta['WeekTransplanted_cos'].values),  # Week cosine\n",
    "        np.array(meta['Year'].values),                  # Year\n",
    "        np.ones(len(meta))                    # Constant feature\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranch_ids = np.array(meta['Ranch'].map(mapping_dict['Ranch']).values)\n",
    "class_ids = np.array(meta['Class'].map(mapping_dict['Class']).values)\n",
    "type_ids = np.array(meta['Type'].map(mapping_dict['Type']).values)\n",
    "variety_ids = np.array(meta['Variety'].map(mapping_dict['Variety']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data = np.stack(meta['ClimateSeries'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_kilos = np.array(smoothed.values)\n",
    "stats = np.array(rf.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fb/78nymm551yn_7vm06j_3sk9w0000gn/T/ipykernel_28002/1386030609.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.features = torch.tensor(features, dtype=torch.float32)\n",
      "/var/folders/fb/78nymm551yn_7vm06j_3sk9w0000gn/T/ipykernel_28002/1386030609.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.climate_data = torch.tensor(climate_data, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "dataset = HarvestDataset(features, ranch_ids, class_ids, type_ids, variety_ids, climate_data, Y_kilos, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "num_epochs = 35\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/35], Loss: 4749.3911\n",
      "Epoch [2/35], Loss: 3432.5801\n",
      "Epoch [3/35], Loss: 2410.7175\n",
      "Epoch [4/35], Loss: 1623.7750\n",
      "Epoch [5/35], Loss: 1053.1553\n",
      "Epoch [6/35], Loss: 686.2574\n",
      "Epoch [7/35], Loss: 461.8655\n",
      "Epoch [8/35], Loss: 333.4060\n",
      "Epoch [9/35], Loss: 260.7676\n",
      "Epoch [10/35], Loss: 215.7010\n",
      "Epoch [11/35], Loss: 179.8210\n",
      "Epoch [12/35], Loss: 146.2065\n",
      "Epoch [13/35], Loss: 114.7944\n",
      "Epoch [14/35], Loss: 85.9111\n",
      "Epoch [15/35], Loss: 62.5411\n",
      "Epoch [16/35], Loss: 44.1192\n",
      "Epoch [17/35], Loss: 30.8082\n",
      "Epoch [18/35], Loss: 23.3675\n",
      "Epoch [19/35], Loss: 20.6739\n",
      "Epoch [20/35], Loss: 20.8396\n",
      "Epoch [21/35], Loss: 21.3061\n",
      "Epoch [22/35], Loss: 21.1009\n",
      "Epoch [23/35], Loss: 20.5861\n",
      "Epoch [24/35], Loss: 19.0982\n",
      "Epoch [25/35], Loss: 15.9990\n",
      "Epoch [26/35], Loss: 11.7015\n",
      "Epoch [27/35], Loss: 7.6847\n",
      "Epoch [28/35], Loss: 4.8758\n",
      "Epoch [29/35], Loss: 3.3325\n",
      "Epoch [30/35], Loss: 2.8363\n",
      "Epoch [31/35], Loss: 3.5452\n",
      "Epoch [32/35], Loss: 4.5225\n",
      "Epoch [33/35], Loss: 4.8288\n",
      "Epoch [34/35], Loss: 4.3018\n",
      "Epoch [35/35], Loss: 3.1606\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize Model\n",
    "model = HarvestModel()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        features, ranch_id, class_id, type_id, variety_id, climate_data, y = batch\n",
    "\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(features, ranch_id, class_id, type_id, variety_id, climate_data)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gotta filter meta too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cherry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
