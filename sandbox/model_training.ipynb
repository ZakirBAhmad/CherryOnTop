{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import src.load as load\n",
    "from src.dataset import HarvestDataset\n",
    "from src.encoder import ClimateEncoder\n",
    "from src.model import HarvestModel, HarvestScheduleModel\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.load as load\n",
    "\n",
    "meta, y, schedule, mapping_dict, reverse_mappings = load.load_data('../data/processed/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "end_harvest\n",
       "20    435\n",
       "18    413\n",
       "21    394\n",
       "19    364\n",
       "17    344\n",
       "22    341\n",
       "23    276\n",
       "16    241\n",
       "24    187\n",
       "15    175\n",
       "25    137\n",
       "14    122\n",
       "26    102\n",
       "13     92\n",
       "12     69\n",
       "27     46\n",
       "28     27\n",
       "30     10\n",
       "29      9\n",
       "11      3\n",
       "31      2\n",
       "32      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule.end_harvest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, mapping_dict, reverse_mappings, test_meta = load.separate_prop('../data/processed/', device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': torch.Size([3032, 5]),\n",
       " 'encoded_features': torch.Size([3032, 6]),\n",
       " 'climate_data': torch.Size([3032, 100, 9]),\n",
       " 'Y_kilos': torch.Size([3032, 40]),\n",
       " 'Y_schedule': torch.Size([3032, 5])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.get_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "encoder = ClimateEncoder().to(device)\n",
    "model = HarvestModel(encoder).to(device)\n",
    "schedule_model = HarvestScheduleModel(encoder).to(device)\n",
    "encoder_param_ids = set(id(p) for p in encoder.parameters())\n",
    "schedule_params = [p for p in schedule_model.parameters() if id(p) not in encoder_param_ids]\n",
    "harvest_params = [p for p in model.parameters() if id(p) not in encoder_param_ids]\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": encoder.parameters(), \"lr\": 1e-4},\n",
    "    {\"params\": harvest_params, \"lr\": 1e-3},\n",
    "    {\"params\": schedule_params, \"lr\": 5e-4},  # <- schedule_model also includes encoder\n",
    "])\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_trial(train_loader, model, schedule_model, criterion, optimizer, num_weeks):\n",
    "    total_harvest_loss = 0\n",
    "    total_schedule_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, encoded_features, climate_data, y, schedule, _= batch\n",
    "        \n",
    "        # Tensors are already on the correct device from the dataset\n",
    "        batch_size, length = y.shape\n",
    "        log_kilos = torch.log1p(y)\n",
    "        week_numbers = torch.arange(0, length, device=y.device).unsqueeze(0).repeat(batch_size,1)\n",
    "        kilo_actuals = torch.stack([y, log_kilos, week_numbers], dim=2)\n",
    "        climate_data = climate_data[:,:num_weeks * 7,:]\n",
    "        kilo_actuals = kilo_actuals[:,:num_weeks,:]\n",
    "\n",
    "        harvest_outputs = model(features, encoded_features, climate_data, kilo_actuals)\n",
    "        schedule_outputs = schedule_model(features, encoded_features, climate_data, kilo_actuals)\n",
    "\n",
    "        loss1 = criterion(harvest_outputs, y)\n",
    "        loss2 = criterion(schedule_outputs, schedule)\n",
    "        \n",
    "        total_loss = loss1 + loss2\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_harvest_loss += loss1.item()\n",
    "        total_schedule_loss += loss2.item()\n",
    "\n",
    "    avg_harvest_loss = total_harvest_loss / len(train_loader)\n",
    "    avg_schedule_loss = total_schedule_loss / len(train_loader)\n",
    "    return avg_harvest_loss, avg_schedule_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sequence(train_loader, model, schedule_model, criterion, optimizer, start_week, num_weeks):\n",
    "    for i in range(start_week, num_weeks):\n",
    "        avg_harvest_loss, avg_schedule_loss = train_trial(train_loader, model, schedule_model, criterion, optimizer, i)\n",
    "    return avg_harvest_loss, avg_schedule_loss\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_loader, model, schedule_model, criterion, num_weeks):\n",
    "    total_harvest_loss = 0\n",
    "    total_schedule_loss = 0\n",
    "    model.eval()\n",
    "    schedule_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            features, encoded_features, climate_data, y, schedule, _= batch\n",
    "            batch_size, length = y.shape\n",
    "            log_kilos = torch.log1p(y)\n",
    "            week_numbers = torch.arange(0, length, device=y.device).unsqueeze(0).repeat(batch_size,1)\n",
    "            kilo_actuals = torch.stack([y, log_kilos, week_numbers], dim=2)\n",
    "            climate_data = climate_data[:,:num_weeks * 7,:]\n",
    "            kilo_actuals = kilo_actuals[:,:num_weeks,:]\n",
    "\n",
    "            harvest_outputs = model(features, encoded_features, climate_data, kilo_actuals)\n",
    "            schedule_outputs = schedule_model(features, encoded_features, climate_data, kilo_actuals)\n",
    "            loss1 = criterion(harvest_outputs, y)\n",
    "            loss2 = criterion(schedule_outputs, schedule)\n",
    "            total_harvest_loss += loss1.item()\n",
    "            total_schedule_loss += loss2.item()\n",
    "\n",
    "    avg_harvest_loss = total_harvest_loss / len(val_loader)\n",
    "    avg_schedule_loss = total_schedule_loss / len(val_loader)\n",
    "    return avg_harvest_loss, avg_schedule_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 10\n",
    "max_weeks = 32\n",
    "num_weeks = 25\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“˜ Epoch 0:\n",
      "  ðŸ”¹ Train   â€” Harvest: 181117.9619, Schedule: 1.3959\n",
      "  ðŸ”¸ Val     â€” Harvest: 309013.1808, Schedule: 5.8081\n",
      "ðŸ“˜ Epoch 1:\n",
      "  ðŸ”¹ Train   â€” Harvest: 166436.1936, Schedule: 1.3760\n",
      "  ðŸ”¸ Val     â€” Harvest: 285401.7699, Schedule: 5.7711\n",
      "ðŸ“˜ Epoch 2:\n",
      "  ðŸ”¹ Train   â€” Harvest: 176635.2651, Schedule: 1.2676\n",
      "  ðŸ”¸ Val     â€” Harvest: 347150.4543, Schedule: 6.7889\n",
      "ðŸ“˜ Epoch 3:\n",
      "  ðŸ”¹ Train   â€” Harvest: 165090.8902, Schedule: 1.2470\n",
      "  ðŸ”¸ Val     â€” Harvest: 308835.4665, Schedule: 7.2081\n",
      "ðŸ“˜ Epoch 4:\n",
      "  ðŸ”¹ Train   â€” Harvest: 163009.8467, Schedule: 1.2358\n",
      "  ðŸ”¸ Val     â€” Harvest: 291573.0170, Schedule: 7.5252\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    schedule_model.train()\n",
    "\n",
    "    # Phase 1 â€” warm-up\n",
    "    harvest_start_loss, schedule_start_loss = train_trial(train_loader, model, schedule_model, criterion, optimizer, 1)\n",
    "    harvest_end_loss, schedule_end_loss = train_trial(train_loader, model, schedule_model, criterion, optimizer, start)\n",
    "\n",
    "    # Phase 2 â€” progressive weekly training\n",
    "    total_harvest_loss = 0\n",
    "    total_schedule_loss = 0\n",
    "\n",
    "    \n",
    "    harvest_loss, schedule_loss = train_sequence(train_loader, model, schedule_model, criterion, optimizer, start, num_weeks)\n",
    "    total_harvest_loss += harvest_loss\n",
    "    total_schedule_loss += schedule_loss\n",
    "   \n",
    "    avg_train_harvest_loss = total_harvest_loss\n",
    "    avg_train_schedule_loss = total_schedule_loss\n",
    "\n",
    "    # Phase 3 â€” circle back\n",
    "    harvest_start_loss, schedule_start_loss = train_trial(train_loader, model, schedule_model, criterion, optimizer, 1)\n",
    "    harvest_end_loss, schedule_end_loss = train_trial(train_loader, model, schedule_model, criterion, optimizer, start)\n",
    "    harvest_end_loss, schedule_end_loss = train_trial(train_loader, model, schedule_model, criterion, optimizer, max_weeks)\n",
    "\n",
    "    # Validation\n",
    "    val_harvest_initial_loss, val_schedule_initial_loss = evaluate(val_loader, model, schedule_model, criterion, 1)\n",
    "    val_harvest_start_loss, val_schedule_start_loss = evaluate(val_loader, model, schedule_model, criterion, start)\n",
    "    val_harvest_loss, val_schedule_loss = evaluate(val_loader, model, schedule_model, criterion, num_weeks)\n",
    "\n",
    "    average_val_loss = (val_harvest_initial_loss + val_harvest_start_loss + val_harvest_loss) / 3\n",
    "    average_val_schedule_loss = (val_schedule_initial_loss + val_schedule_start_loss + val_schedule_loss) / 3\n",
    "    # Track losses\n",
    "    train_losses.append((avg_train_harvest_loss, avg_train_schedule_loss))\n",
    "    val_losses.append((average_val_loss, average_val_schedule_loss))\n",
    "\n",
    "    print(f\"ðŸ“˜ Epoch {epoch}:\")\n",
    "    print(f\"  ðŸ”¹ Train   â€” Harvest: {avg_train_harvest_loss:.4f}, Schedule: {avg_train_schedule_loss:.4f}\")\n",
    "    print(f\"  ðŸ”¸ Val     â€” Harvest: {average_val_loss:.4f}, Schedule: {average_val_schedule_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cherry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
