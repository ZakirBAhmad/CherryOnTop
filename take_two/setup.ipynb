{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.load as load\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta, y, schedule, mappings, reverse_mappings = load.load_data('../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransplantDate</th>\n",
       "      <th>Parcel</th>\n",
       "      <th>Lot</th>\n",
       "      <th>ProducerCode</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Ha</th>\n",
       "      <th>Class</th>\n",
       "      <th>Type</th>\n",
       "      <th>WeekTransplanted</th>\n",
       "      <th>WeekCos</th>\n",
       "      <th>WeekSin</th>\n",
       "      <th>Year</th>\n",
       "      <th>ClimateSeries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-28</td>\n",
       "      <td>N02</td>\n",
       "      <td>7</td>\n",
       "      <td>OAP</td>\n",
       "      <td>Shiren</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>CHE</td>\n",
       "      <td>Cherry Rojo</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.608123e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>[[-0.3827101525, -1.1992770129, 0.0, 0.0, 0.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>Z18</td>\n",
       "      <td>6</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Felicity</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>CHE</td>\n",
       "      <td>Cherry Rojo</td>\n",
       "      <td>7</td>\n",
       "      <td>6.631227e-01</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>2013</td>\n",
       "      <td>[[-0.2535675497, -0.8592687109, 0.0, 0.0, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>Z18</td>\n",
       "      <td>6</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Shiren</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>CHE</td>\n",
       "      <td>Cherry Rojo</td>\n",
       "      <td>7</td>\n",
       "      <td>6.631227e-01</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>2013</td>\n",
       "      <td>[[-0.2535675497, -0.8592687109, 0.0, 0.0, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>Z18</td>\n",
       "      <td>2</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>BSUF</td>\n",
       "      <td>Uva Roja</td>\n",
       "      <td>7</td>\n",
       "      <td>6.631227e-01</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>2013</td>\n",
       "      <td>[[0.3125368926, -0.0596579057, 0.0, 0.0, -0.54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>Z18</td>\n",
       "      <td>2</td>\n",
       "      <td>ZJL</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>BSUF</td>\n",
       "      <td>Uva Roja</td>\n",
       "      <td>7</td>\n",
       "      <td>6.631227e-01</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>2013</td>\n",
       "      <td>[[0.3125368926, -0.0596579057, 0.0, 0.0, -0.54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>S12</td>\n",
       "      <td>4</td>\n",
       "      <td>SGB</td>\n",
       "      <td>Top 2323</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>CHE</td>\n",
       "      <td>Cherry Rosa</td>\n",
       "      <td>30</td>\n",
       "      <td>-8.854560e-01</td>\n",
       "      <td>-0.464723</td>\n",
       "      <td>2024</td>\n",
       "      <td>[[0.8452649894, 0.93700445, 0.0, 0.0, 0.485896...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>S12</td>\n",
       "      <td>4</td>\n",
       "      <td>SGB</td>\n",
       "      <td>Yoyomo</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>BSUF</td>\n",
       "      <td>Uva Amarilla</td>\n",
       "      <td>30</td>\n",
       "      <td>-8.854560e-01</td>\n",
       "      <td>-0.464723</td>\n",
       "      <td>2024</td>\n",
       "      <td>[[0.8452649894, 0.93700445, 0.0, 0.0, 0.485896...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>S12</td>\n",
       "      <td>7</td>\n",
       "      <td>SGB</td>\n",
       "      <td>King</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>BSUF</td>\n",
       "      <td>Uva Roja</td>\n",
       "      <td>31</td>\n",
       "      <td>-8.229839e-01</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>2024</td>\n",
       "      <td>[[0.3676142667, 0.3320816298, 0.0, 0.0, 0.5941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>S12</td>\n",
       "      <td>8</td>\n",
       "      <td>SGB</td>\n",
       "      <td>King</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>BSUF</td>\n",
       "      <td>Uva Roja</td>\n",
       "      <td>31</td>\n",
       "      <td>-8.229839e-01</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>2024</td>\n",
       "      <td>[[0.3676142667, 0.3320816298, 0.0, 0.0, 0.5941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>S12</td>\n",
       "      <td>8</td>\n",
       "      <td>SGB</td>\n",
       "      <td>Tymoty</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>CHE</td>\n",
       "      <td>Cherry Rojo</td>\n",
       "      <td>31</td>\n",
       "      <td>-8.229839e-01</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>2024</td>\n",
       "      <td>[[0.3676142667, 0.3320816298, 0.0, 0.0, 0.5941...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3790 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TransplantDate Parcel  Lot ProducerCode    Variety      Ha Class  \\\n",
       "0        2012-03-28    N02    7          OAP     Shiren  0.1330   CHE   \n",
       "1        2013-02-13    Z18    6          ZJL   Felicity  0.3938   CHE   \n",
       "2        2013-02-13    Z18    6          ZJL     Shiren  0.3938   CHE   \n",
       "3        2013-02-15    Z18    2          ZJL  Amsterdam  0.2700  BSUF   \n",
       "4        2013-02-15    Z18    2          ZJL     Olivia  0.5400  BSUF   \n",
       "...             ...    ...  ...          ...        ...     ...   ...   \n",
       "3785     2024-07-25    S12    4          SGB   Top 2323  0.1530   CHE   \n",
       "3786     2024-07-25    S12    4          SGB     Yoyomo  0.1020  BSUF   \n",
       "3787     2024-07-29    S12    7          SGB       King  0.5100  BSUF   \n",
       "3788     2024-07-29    S12    8          SGB       King  0.0306  BSUF   \n",
       "3789     2024-07-29    S12    8          SGB     Tymoty  0.3978   CHE   \n",
       "\n",
       "              Type  WeekTransplanted       WeekCos   WeekSin  Year  \\\n",
       "0      Cherry Rojo                13 -1.608123e-16  1.000000  2012   \n",
       "1      Cherry Rojo                 7  6.631227e-01  0.748511  2013   \n",
       "2      Cherry Rojo                 7  6.631227e-01  0.748511  2013   \n",
       "3         Uva Roja                 7  6.631227e-01  0.748511  2013   \n",
       "4         Uva Roja                 7  6.631227e-01  0.748511  2013   \n",
       "...            ...               ...           ...       ...   ...   \n",
       "3785   Cherry Rosa                30 -8.854560e-01 -0.464723  2024   \n",
       "3786  Uva Amarilla                30 -8.854560e-01 -0.464723  2024   \n",
       "3787      Uva Roja                31 -8.229839e-01 -0.568065  2024   \n",
       "3788      Uva Roja                31 -8.229839e-01 -0.568065  2024   \n",
       "3789   Cherry Rojo                31 -8.229839e-01 -0.568065  2024   \n",
       "\n",
       "                                          ClimateSeries  \n",
       "0     [[-0.3827101525, -1.1992770129, 0.0, 0.0, 0.41...  \n",
       "1     [[-0.2535675497, -0.8592687109, 0.0, 0.0, -0.1...  \n",
       "2     [[-0.2535675497, -0.8592687109, 0.0, 0.0, -0.1...  \n",
       "3     [[0.3125368926, -0.0596579057, 0.0, 0.0, -0.54...  \n",
       "4     [[0.3125368926, -0.0596579057, 0.0, 0.0, -0.54...  \n",
       "...                                                 ...  \n",
       "3785  [[0.8452649894, 0.93700445, 0.0, 0.0, 0.485896...  \n",
       "3786  [[0.8452649894, 0.93700445, 0.0, 0.0, 0.485896...  \n",
       "3787  [[0.3676142667, 0.3320816298, 0.0, 0.0, 0.5941...  \n",
       "3788  [[0.3676142667, 0.3320816298, 0.0, 0.0, 0.5941...  \n",
       "3789  [[0.3676142667, 0.3320816298, 0.0, 0.0, 0.5941...  \n",
       "\n",
       "[3790 rows x 13 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3790 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6     7     8      9  ...   30   31  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0    0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0    0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0    0.0  ...  0.0  0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0    0.0  ...  0.0  0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0    0.0  ...  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...   ...   ...    ...  ...  ...  ...   \n",
       "3785  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0    0.0  ...  0.0  0.0   \n",
       "3786  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0    0.0  ...  0.0  0.0   \n",
       "3787  0.0  0.0  0.0  0.0  0.0  0.0  0.0  33.0  88.0    0.0  ...  0.0  0.0   \n",
       "3788  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  143.0  ...  0.0  0.0   \n",
       "3789  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  36.0  108.0  ...  0.0  0.0   \n",
       "\n",
       "       32   33   34   35   36   37   38   39  \n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "3785  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3786  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3787  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3788  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3789  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3790 rows x 40 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3790, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3790, 40)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kilo_dist = (y.values / y.values.sum(axis=1, keepdims=True)).cumsum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       14768.0\n",
       "1       21302.0\n",
       "2       24530.0\n",
       "3        7232.0\n",
       "4       10464.0\n",
       "         ...   \n",
       "3785     1000.0\n",
       "3786      396.0\n",
       "3787     7789.0\n",
       "3788     2267.0\n",
       "3789     9736.0\n",
       "Length: 3790, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Take2(Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self, \n",
    "                 features,\n",
    "                 encoded_features,\n",
    "                 climate_data,\n",
    "                 yield_dist,       \n",
    "                 kilo_dist,\n",
    "                 yield_log,       \n",
    "                 schedule\n",
    "                ):\n",
    "\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.encoded_features = torch.tensor(encoded_features, dtype=torch.long)\n",
    "        self.climate_data = torch.tensor(climate_data, dtype=torch.float32)\n",
    "        self.yield_dist = torch.tensor(yield_dist, dtype=torch.float32).unsqueeze(2)\n",
    "        self.kilo_dist = torch.tensor(kilo_dist, dtype=torch.float32).unsqueeze(2)\n",
    "\n",
    "        self.Y_yield_log = torch.tensor(yield_log, dtype=torch.float32)\n",
    "        self.Y_schedule = torch.tensor(schedule, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        climate_data = self.climate_data[idx]\n",
    "\n",
    "        return (\n",
    "            self.features[idx],\n",
    "            self.encoded_features[idx],\n",
    "            climate_data,\n",
    "            self.yield_dist[idx],\n",
    "            self.kilo_dist[idx],\n",
    "            self.Y_yield_log[idx],\n",
    "            self.Y_schedule[idx],\n",
    "            idx\n",
    "        )\n",
    "    \n",
    "    def get_shapes(self):\n",
    "\n",
    "        shapes = {\n",
    "            'features': self.features.shape,\n",
    "            'encoded_features': self.encoded_features.shape,\n",
    "            'climate_data': self.climate_data.shape,\n",
    "            'yield_dist': self.yield_dist.shape,\n",
    "            'kilo_dist': self.kilo_dist.shape,\n",
    "            'yield_log': self.Y_yield_log.shape,\n",
    "            'schedule': self.Y_schedule.shape\n",
    "        }\n",
    "        return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.column_stack([\n",
    "    meta['Ha'].to_numpy(),  # Hectares\n",
    "    meta['WeekSin'].to_numpy(),  # Week sine\n",
    "    meta['WeekCos'].to_numpy(),  # Week cosine\n",
    "    meta['Year'].to_numpy() - 2010,                  # Year\n",
    "    np.ones(len(meta))                    # Constant feature\n",
    "])\n",
    "mapped_arrays = [meta[column].astype(str).map(mappings[column]).to_numpy() for column in ['ProducerCode','Parcel','Class','Type','Variety']]\n",
    "encoded_features = np.column_stack(mapped_arrays)\n",
    "\n",
    "climate_data = np.array(meta.ClimateSeries.to_list())\n",
    "schedule_data = schedule.values\n",
    "kilo_dist = (y.to_numpy() / y.to_numpy().sum(axis=1, keepdims=True)).cumsum(axis=1)\n",
    "yield_dist = np.log1p(y.to_numpy() / meta['Ha'].to_numpy()[:, np.newaxis])\n",
    "yield_log = np.log1p(y.to_numpy().sum(axis=1) / meta['Ha'].to_numpy())\n",
    "\n",
    "data_set = Data_Take2(\n",
    "    features,\n",
    "    encoded_features,\n",
    "    climate_data,\n",
    "    yield_dist,\n",
    "    kilo_dist,\n",
    "    yield_log,\n",
    "    schedule_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3790, 40, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.kilo_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClimateEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim=5,\n",
    "                 embedding_dim=12,\n",
    "                 hidden_dim=32,\n",
    "                 n_ranches=13,\n",
    "                 n_parcels=44,\n",
    "                 n_classes=2,\n",
    "                 n_types=14,\n",
    "                 n_varieties=59,\n",
    "                 climate_input_dim=9,\n",
    "                 climate_hidden_dim=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # Feature processing\n",
    "        self.feature_encoder = nn.Sequential(\n",
    "            weight_norm(nn.Linear(input_dim, hidden_dim)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Climate GRU\n",
    "        self.climate_gru = nn.GRU(\n",
    "            input_size=climate_input_dim, \n",
    "            hidden_size=climate_hidden_dim,\n",
    "            num_layers=2,\n",
    "            dropout=0.2,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Embedding dimensions\n",
    "        self.ranch_dim = embedding_dim  # 12 ranches\n",
    "        self.parcel_dim = embedding_dim  # 12 ranches\n",
    "        self.class_dim = embedding_dim  # 2 classes\n",
    "        self.type_dim = embedding_dim  # 14 types\n",
    "        self.variety_dim = embedding_dim  # 38 varieties\n",
    "\n",
    "        self.ranch_emb = nn.Embedding(n_ranches, self.ranch_dim)\n",
    "        self.parcel_emb = nn.Embedding(n_parcels, self.parcel_dim)\n",
    "\n",
    "        self.parcel_to_ranch = weight_norm(nn.Linear(self.parcel_dim, self.ranch_dim))\n",
    "\n",
    "        self.class_emb = nn.Embedding(n_classes, self.class_dim)\n",
    "        self.type_emb = nn.Embedding(n_types, self.type_dim)\n",
    "        self.variety_emb = nn.Embedding(n_varieties, self.variety_dim)\n",
    "\n",
    "        self.type_to_class = weight_norm(nn.Linear(self.type_dim, self.class_dim))\n",
    "        self.variety_to_type = weight_norm(nn.Linear(self.variety_dim, self.type_dim))\n",
    "\n",
    "        self.combined_dim = (\n",
    "            hidden_dim +             \n",
    "            climate_hidden_dim +     \n",
    "            self.ranch_dim + \n",
    "            self.parcel_dim + \n",
    "            self.class_dim + \n",
    "            self.type_dim + \n",
    "            self.variety_dim\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, features, encoded_features, climate_data):\n",
    "        \"\"\"\n",
    "        features: (batch_size, 5)\n",
    "        climate_data: (batch_size, 100, )\n",
    "        \"\"\"\n",
    "\n",
    "        # Static feature encoder\n",
    "        h_features = self.feature_encoder(features)\n",
    "\n",
    "        # Climate GRU\n",
    "        batch_size = climate_data.size(0)\n",
    "        h0 = torch.zeros(2, batch_size, self.climate_gru.hidden_size).to(climate_data.device)\n",
    "        out, _ = self.climate_gru(climate_data, h0)  # out: (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        # Take last timestep\n",
    "        climate_out = out[:, -1, :]  # (batch_size, climate_hidden_dim)\n",
    "\n",
    "        ranch_id, parcel_id, class_id, type_id, variety_id = encoded_features.T\n",
    "\n",
    "        # Embeddings\n",
    "        r_emb = self.ranch_emb(ranch_id)\n",
    "        p_emb = self.parcel_emb(parcel_id)\n",
    "\n",
    "        p_influence_on_ranch = self.parcel_to_ranch(p_emb)\n",
    "        r_emb = r_emb + p_influence_on_ranch\n",
    "\n",
    "        c_emb = self.class_emb(class_id)\n",
    "        t_emb = self.type_emb(type_id)\n",
    "        v_emb = self.variety_emb(variety_id)\n",
    "\n",
    "        # Hierarchy\n",
    "        v_influence_on_type = self.variety_to_type(v_emb)\n",
    "        t_emb = t_emb + v_influence_on_type\n",
    "\n",
    "        t_influence_on_class = self.type_to_class(t_emb)\n",
    "        c_emb = c_emb + t_influence_on_class\n",
    "\n",
    "        # Combine all features\n",
    "        combined = torch.cat([\n",
    "            h_features,\n",
    "            climate_out,\n",
    "            r_emb,\n",
    "            p_emb,\n",
    "            c_emb,\n",
    "            t_emb,\n",
    "            v_emb\n",
    "        ], dim=-1)\n",
    "\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_dim=40,\n",
    "                 hidden_size=32,\n",
    "                 batch_size=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.encoder = ClimateEncoder()\n",
    "\n",
    "        self.kilo_gru = nn.GRU(\n",
    "            input_size=1,\n",
    "            num_layers=2,\n",
    "            dropout=0.2,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.kilo_output = nn.Sequential(\n",
    "            weight_norm(nn.Linear(self.encoder.combined_dim+hidden_size, batch_size)),\n",
    "            nn.ReLU(),\n",
    "            weight_norm(nn.Linear(batch_size, output_dim))\n",
    "        )\n",
    "\n",
    "    def forward(self, features, encoded_features, climate_data, kilo_gru_input):\n",
    "        \"\"\"\n",
    "        features: (batch_size, 5)\n",
    "        climate_data: (batch_size, 100, 10)\n",
    "        kilo_dist_input: (batch_size, 40, 2)\n",
    "        \"\"\"\n",
    "        encoded = self.encoder(features, encoded_features, climate_data)\n",
    "        batch_size = climate_data.size(0)\n",
    "        \n",
    "        # Ensure h0 is on the same device as the input\n",
    "        h0 = torch.zeros(2, batch_size, self.kilo_gru.hidden_size, device=kilo_gru_input.device)\n",
    "        out, _ = self.kilo_gru(kilo_gru_input, h0)\n",
    "        result = out[:, -1, :]\n",
    "    \n",
    "        kilo_output = self.kilo_output(torch.cat((encoded,result),dim=1))\n",
    "        return kilo_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduleModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_dim=5,\n",
    "                 batch_size=32,\n",
    "                 hidden_size=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.encoder = ClimateEncoder()\n",
    "\n",
    "        self.kilo_gru = nn.GRU(\n",
    "            input_size=1,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,\n",
    "            dropout=0.2,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.schedule_output = nn.Sequential(\n",
    "            weight_norm(nn.Linear(self.encoder.combined_dim+hidden_size, batch_size)),\n",
    "            nn.ReLU(),\n",
    "            weight_norm(nn.Linear(batch_size, output_dim))\n",
    "        )\n",
    "\n",
    "    def forward(self, features, encoded_features, climate_data, kilo_gru_input):\n",
    "        \"\"\"\n",
    "        features: (batch_size, 5)\n",
    "        climate_data: (batch_size, 100, 10)\n",
    "        kilo_gru_input: (batch_size, [5:20], 3)\n",
    "        kilo_model_output: (batch_size, 40)\n",
    "        \"\"\"\n",
    "        encoded = self.encoder(features, encoded_features, climate_data)\n",
    "        batch_size = climate_data.size(0)\n",
    "        \n",
    "        # Ensure h0 is on the same device as the input\n",
    "        h0 = torch.zeros(2, batch_size, self.kilo_gru.hidden_size, device=kilo_gru_input.device)\n",
    "        out, _ = self.kilo_gru(kilo_gru_input, h0)\n",
    "        result = out[:, -1, :]\n",
    "    \n",
    "        schedule = self.schedule_output(torch.cat((encoded,result),dim=1))\n",
    "        return schedule\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YieldModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 batch_size=32,\n",
    "                 hidden_size=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = ClimateEncoder()\n",
    "        self.yield_gru = nn.GRU(\n",
    "            input_size=1,\n",
    "            hidden_size=32,\n",
    "            num_layers=2,\n",
    "            dropout=0.2,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.final_output = nn.Sequential(\n",
    "            weight_norm(nn.Linear(self.encoder.combined_dim+hidden_size, batch_size)),\n",
    "            nn.ReLU(),\n",
    "            weight_norm(nn.Linear(batch_size, 1))\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, encoded_features, climate_data, yield_gru_input):\n",
    "        encoded = self.encoder(features, encoded_features, climate_data)\n",
    "        batch_size = climate_data.size(0)\n",
    "        h0 = torch.zeros(2, batch_size, self.yield_gru.hidden_size)\n",
    "        out, _ = self.yield_gru(yield_gru_input, h0)\n",
    "        result = out[:, -1, :]\n",
    "        yield_output = self.final_output(torch.cat((encoded, result), dim=1))\n",
    "        return yield_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': torch.Size([3790, 5]),\n",
       " 'encoded_features': torch.Size([3790, 5]),\n",
       " 'climate_data': torch.Size([3790, 100, 9]),\n",
       " 'yield_dist': torch.Size([3790, 40, 1]),\n",
       " 'kilo_dist': torch.Size([3790, 40, 1]),\n",
       " 'yield_log': torch.Size([3790]),\n",
       " 'schedule': torch.Size([3790, 5])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.get_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zakir/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(data_set, batch_size=32, shuffle=True)\n",
    "model = YieldModel()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3,weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_weeks = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 793817033.0084034\n",
      "Epoch 2, Loss: 411957184.4033613\n",
      "Epoch 3, Loss: 343710810.68907565\n",
      "Epoch 4, Loss: 327882487.39495796\n",
      "Epoch 5, Loss: 327370522.8907563\n",
      "Epoch 6, Loss: 314703600.26890755\n",
      "Epoch 7, Loss: 303755938.75630254\n",
      "Epoch 8, Loss: 293399165.4453781\n",
      "Epoch 9, Loss: 304933595.0252101\n",
      "Epoch 10, Loss: 291552681.5462185\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        features, encoded_features, climate_data, yield_dist, kilo_dist, yield_log, schedule,_ = batch\n",
    "        \n",
    "        yield_gru_input = yield_dist[:,:num_weeks,:]\n",
    "        yield_output = model(features, encoded_features, climate_data, yield_gru_input)\n",
    "        yield_output = yield_output.squeeze(-1)\n",
    "        loss = criterion(torch.exp(yield_output), torch.exp(yield_log))\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zakir/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "dist_model = DistModel()\n",
    "\n",
    "dist_optimizer = torch.optim.Adam(dist_model.parameters(), lr=1e-3,weight_decay=1e-4)\n",
    "\n",
    "dist_scheduler = torch.optim.lr_scheduler.StepLR(dist_optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.09499948550829616\n",
      "Epoch 2, Loss: 0.016040221631464336\n",
      "Epoch 3, Loss: 0.015300306984606911\n",
      "Epoch 4, Loss: 0.0149829226757298\n",
      "Epoch 5, Loss: 0.014755141389157091\n",
      "Epoch 6, Loss: 0.014639073935877375\n",
      "Epoch 7, Loss: 0.014281494284690428\n",
      "Epoch 8, Loss: 0.013998339218752725\n",
      "Epoch 9, Loss: 0.013788929506510245\n",
      "Epoch 10, Loss: 0.013617030556211952\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        features, encoded_features, climate_data, yield_dist, kilo_dist, yield_log, schedule,_ = batch\n",
    "        \n",
    "        kilo_gru_input = kilo_dist[:,:num_weeks,:]\n",
    "        dist_output = dist_model(features, encoded_features, climate_data, kilo_gru_input)\n",
    "        dist_output = dist_output.squeeze(-1)\n",
    "        loss = criterion(dist_output, kilo_dist.squeeze(-1))\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(dist_model.parameters(), max_norm=1.0)\n",
    "\n",
    "        dist_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        dist_optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    dist_scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zakir/anaconda3/envs/cherry/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "sched_model = ScheduleModel()\n",
    "\n",
    "sched_optimizer = torch.optim.Adam(sched_model.parameters(), lr=1e-3,weight_decay=1e-4)\n",
    "\n",
    "sched_scheduler = torch.optim.lr_scheduler.StepLR(sched_optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 53.16181524861761\n",
      "Epoch 2, Loss: 5.803398048176485\n",
      "Epoch 3, Loss: 5.222241886523592\n",
      "Epoch 4, Loss: 4.987875635884389\n",
      "Epoch 5, Loss: 4.851659502301898\n",
      "Epoch 6, Loss: 4.774711628921893\n",
      "Epoch 7, Loss: 4.683125724311636\n",
      "Epoch 8, Loss: 4.622283482751927\n",
      "Epoch 9, Loss: 4.578349255714096\n",
      "Epoch 10, Loss: 4.53223679246021\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        features, encoded_features, climate_data, yield_dist, kilo_dist, yield_log, schedule,_ = batch\n",
    "        \n",
    "        kilo_gru_input = kilo_dist[:,:num_weeks,:]\n",
    "        sched_output = sched_model(features, encoded_features, climate_data, kilo_gru_input)\n",
    "        sched_output = sched_output.squeeze(-1)\n",
    "        loss = criterion(sched_output, schedule)\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(sched_model.parameters(), max_norm=1.0)\n",
    "\n",
    "        sched_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        sched_optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    sched_scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cherry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
